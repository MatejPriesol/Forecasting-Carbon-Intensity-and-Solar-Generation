{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train-test-split/TrainSet.csv\", sep=\",\")\n",
    "validation = pd.read_csv(\"../data/train-test-split/ValidationSet.csv\", sep=\",\")\n",
    "test = pd.read_csv(\"../data/train-test-split/TestSet.csv\", sep=\",\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8878ce79c1e517d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "NUM_OF_TIMESTEPS_INPUT = 48\n",
    "NUM_OF_TIMESTEPS_OUTPUT = 24\n",
    "\n",
    "THRESHOLD = 0.4   # For feature selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eb19b54d6ddc902"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the independent variables\n",
    "\n",
    "columns_to_predict = [\"kg_CO2/kWh\", \"Avg solar generation\"]\n",
    "\n",
    "independent_variables = []\n",
    "\n",
    "for column in train:\n",
    "    if abs(train[column].corr(train[columns_to_predict[0]])) > THRESHOLD:\n",
    "        independent_variables.append(column)\n",
    "\n",
    "independent_variables = [var for var in independent_variables if var not in columns_to_predict]\n",
    "    \n",
    "if \"Index\" in independent_variables:\n",
    "    independent_variables.remove(\"Index\")\n",
    "if \"Solar Generation (W/kW)_1\" in independent_variables:\n",
    "    independent_variables.remove(\"Solar Generation (W/kW)_1\")\n",
    "if \"Solar Generation (W/kW)_2\" in independent_variables:\n",
    "    independent_variables.remove(\"Solar Generation (W/kW)_2\")\n",
    "if \"Solar Generation (W/kW)_3\" in independent_variables:\n",
    "    independent_variables.remove(\"Solar Generation (W/kW)_3\")\n",
    "if \"Hour_2\" in independent_variables:\n",
    "    independent_variables.remove(\"Hour_2\")\n",
    "if \"Hour_3\" in independent_variables:\n",
    "    independent_variables.remove(\"Hour_3\")\n",
    "    \n",
    "print(independent_variables)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1e33045de75032a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the X and Y for all sets\n",
    "\n",
    "# Train set\n",
    "X_train_default = train[independent_variables]\n",
    "Y_train_default = train[columns_to_predict]\n",
    "\n",
    "# Validation set, also include the data from train that was used only as output to get more datapoints\n",
    "X_val_default = pd.concat([X_train_default.tail(NUM_OF_TIMESTEPS_OUTPUT), validation[independent_variables]], ignore_index=True)\n",
    "Y_val_default = pd.concat([Y_train_default.tail(NUM_OF_TIMESTEPS_OUTPUT), validation[columns_to_predict]], ignore_index=True)\n",
    "\n",
    "# Test set, also include the data from train that was used only as output to get more datapoints\n",
    "X_test_default = pd.concat([X_val_default.tail(NUM_OF_TIMESTEPS_OUTPUT), test[independent_variables]], ignore_index=True)\n",
    "Y_test_default = pd.concat([Y_val_default.tail(NUM_OF_TIMESTEPS_OUTPUT), test[columns_to_predict]], ignore_index=True)\n",
    "\n",
    "NUM_OF_ROWS_TRAIN, NUM_OF_FEATURES = X_train_default.shape\n",
    "\n",
    "print(X_train_default.shape)\n",
    "print(X_val_default.shape)\n",
    "print(X_test_default.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d8d2bf1598aca2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to prepare the data into batches that will be passed into the model\n",
    "\n",
    "def create_sequences(input_data, output_data, timesteps_input, timesteps_output):\n",
    "    sequences, targets = [], []\n",
    "    for i in range(len(input_data) - timesteps_input - timesteps_output + 1):\n",
    "        seq = input_data[i:i + timesteps_input]\n",
    "        target = output_data[i + timesteps_input: i + timesteps_input + timesteps_output]\n",
    "        sequences.append(seq)\n",
    "        targets.append(target)\n",
    "\n",
    "    return np.array(sequences), np.array(targets)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9083707d0c36e95a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, Y_train = create_sequences(X_train_default, Y_train_default, NUM_OF_TIMESTEPS_INPUT, NUM_OF_TIMESTEPS_OUTPUT)\n",
    "X_val, Y_val = create_sequences(X_val_default, Y_val_default, NUM_OF_TIMESTEPS_INPUT, NUM_OF_TIMESTEPS_OUTPUT)\n",
    "X_test, Y_test = create_sequences(X_test_default, Y_test_default, NUM_OF_TIMESTEPS_INPUT, NUM_OF_TIMESTEPS_OUTPUT)\n",
    "\n",
    "print(f\"X_train = {X_train.shape}, Y_train = {Y_train.shape}\\n\"\n",
    "      f\"X_val = {X_val.shape}, Y_val = {Y_val.shape}\\n\"\n",
    "      f\"X_test = {X_test.shape}, Y_test = {Y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "919f3327d6b102f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras import layers, models\n",
    "import time\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 4, test_size=24) # For cross-validation\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience = 4)\n",
    "\n",
    "# keep track of the losses\n",
    "loss = []\n",
    "val_loss = []\n",
    "loss_1 = []\n",
    "val_loss_1 = []\n",
    "loss_2 = []\n",
    "val_loss_2 = []\n",
    "\n",
    "# Input layer\n",
    "input_layer = layers.Input(shape=(NUM_OF_TIMESTEPS_INPUT, NUM_OF_FEATURES))\n",
    "\n",
    "# GRU layers for variable 1\n",
    "gru1 = layers.GRU(48, activation='leaky_relu', return_sequences=True)(input_layer)\n",
    "gru2 = layers.GRU(48, activation='leaky_relu', return_sequences=True)(gru1)\n",
    "gru3 = layers.GRU(24, activation='leaky_relu', return_sequences=False)(gru2)\n",
    "output_variable1 = layers.Dense(24, name='output_variable1')(gru3)\n",
    "\n",
    "# GRU layers for variable 2\n",
    "gru4 = layers.GRU(48, activation='leaky_relu', return_sequences=True)(input_layer)\n",
    "gru5 = layers.GRU(48, activation='leaky_relu', return_sequences=True)(gru4)\n",
    "gru6 = layers.GRU(24, activation='leaky_relu', return_sequences=False)(gru5)\n",
    "output_variable2 = layers.Dense(24, name='output_variable2')(gru6)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "model = models.Model(inputs=input_layer, outputs=[output_variable1, output_variable2])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={'output_variable1': 'mean_squared_error', 'output_variable2': 'mean_squared_error'}\n",
    ")\n",
    "\n",
    "# keep track of the training time      \n",
    "start = time.time()\n",
    "\n",
    "for train_data, test_data in tscv.split(X_train):\n",
    "    X_train_current_split, X_test_current_split = X_train[train_data], X_train[test_data]\n",
    "    y_train_current_split, y_test_current_split = Y_train[train_data], Y_train[test_data]\n",
    "    \n",
    "    history = model.fit(X_train_current_split, y={\"output_variable1\": y_train_current_split[:, :, 0], \n",
    "                                                  \"output_variable2\": y_train_current_split[:, :, 1]},\n",
    "              epochs=50, \n",
    "              validation_data=(\n",
    "                  X_test_current_split,\n",
    "                {\n",
    "                    \"output_variable1\": y_test_current_split[:, :, 0],\n",
    "                    \"output_variable2\": y_test_current_split[:, :, 1],\n",
    "                },\n",
    "              ),\n",
    "              verbose=1,\n",
    "              callbacks=callback\n",
    "    )\n",
    "    loss.append(model.history.history['loss'])\n",
    "    val_loss.append(model.history.history['val_loss'])\n",
    "    \n",
    "    loss_1.append(model.history.history['output_variable1_loss'])\n",
    "    val_loss_1.append(model.history.history['val_output_variable1_loss'])\n",
    "    \n",
    "    loss_2.append(model.history.history['output_variable2_loss'])\n",
    "    val_loss_2.append(model.history.history['val_output_variable2_loss'])\n",
    "    \n",
    "end = time.time()\n",
    "\n",
    "print(f\"Training time = {end - start} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "779f35bf4f1bc980"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, column in enumerate(loss):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(column, label=\"Train error\")\n",
    "    plt.plot(val_loss[i], label=\"Validation error\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.title(f'Validation loss for Fold {i+1}')\n",
    "\n",
    "plt.suptitle('Total Validation Loss across folds in GRU', fontsize=18, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c9dade2e0e346c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, column in enumerate(loss_1):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(column, label=\"Train error\")\n",
    "    plt.plot(val_loss_1[i], label=\"Validation error\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.title(f'Validation loss for Fold {i+1}')\n",
    "\n",
    "plt.suptitle('Validation Loss across folds for Carbon Intensity in GRU', fontsize=18, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5187c6d9d1179844"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, column in enumerate(loss_2):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.plot(column, label=\"Train error\")\n",
    "    plt.plot(val_loss_2[i], label=\"Validation error\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation loss (MSE)')\n",
    "    plt.legend()\n",
    "    plt.title(f'Validation loss for Fold {i+1}')\n",
    "\n",
    "plt.suptitle('Validation Loss across folds for Solar Generation in GRU', fontsize=18, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "174dd3d256bd68d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Export the loss\n",
    "\n",
    "headers = []\n",
    "loss_df = []\n",
    "\n",
    "for i, column in enumerate(loss):\n",
    "    loss_df.append(column)\n",
    "    loss_df.append(val_loss[i])\n",
    "    headers.append(f\"Fold {i} Train\")\n",
    "    headers.append(f\"Fold {i} Val\")\n",
    "    \n",
    "\n",
    "loss_df = pd.DataFrame(loss_df).T\n",
    "loss_df.to_csv('../data/results/loss_gru.csv', index=False, header=headers)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79a37e7b2f130e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "predictions_1 = []\n",
    "predictions_2 = []\n",
    "\n",
    "for i in range(len(Y_val)):\n",
    "    current_batch = X_val[i].reshape((1, NUM_OF_TIMESTEPS_INPUT, NUM_OF_FEATURES))\n",
    "    curr_pred1, curr_pred2 = model.predict(current_batch)\n",
    "    predictions_1.append(curr_pred1)\n",
    "    predictions_2.append(curr_pred2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bf256ff8260eda2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the evaluation predictions for CI\n",
    "\n",
    "plt.figure(figsize=(20, 48))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for num, column in enumerate(predictions_1):\n",
    "    plt.subplot(9, 3, i)\n",
    "    i += 1\n",
    "    plt.plot(column[0], label=\"Prediction\")\n",
    "    plt.plot(Y_val[num, :, 0], label=\"Actual\")\n",
    "    plt.xlabel('Timestamp', fontsize=20)\n",
    "    plt.ylabel('Carbon Intensity (kg/kWh)', fontsize=20)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title(f'Prediction number {num+1}', fontsize=22)\n",
    "    plt.tick_params(labelsize=16)\n",
    "\n",
    "plt.suptitle('Predicted and actual Solar Generation', fontsize=26, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e211b5fad82c4c3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the evaluation predictions for SG\n",
    "\n",
    "plt.figure(figsize=(20, 48))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for num, column in enumerate(predictions_2):\n",
    "    plt.subplot(9, 3, i)\n",
    "    i += 1\n",
    "    plt.plot(column[0], label=\"Prediction\")\n",
    "    plt.plot(Y_val[num, :, 1], label=\"Actual\")\n",
    "    plt.xlabel('Timestamp', fontsize=20)\n",
    "    plt.ylabel('Carbon Intensity (kg/kWh)', fontsize=20)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title(f'Prediction number {num+1}', fontsize=22)\n",
    "    plt.tick_params(labelsize=16)\n",
    "\n",
    "plt.suptitle('Predicted and actual Solar Generation', fontsize=26, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c96fd1226aa09df",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the RMSE\n",
    "\n",
    "rmse = 0\n",
    "for i in range(len(predictions_1)):\n",
    "    rmse += sqrt(mean_squared_error(predictions_1[i][0], Y_val[i, :, 0]))\n",
    "\n",
    "rmse /= len(predictions_1)    \n",
    "print(f\"RMSE for {columns_to_predict[0]} = {rmse}\")\n",
    "\n",
    "rmse = 0\n",
    "for i in range(len(predictions_2)):\n",
    "    rmse += sqrt(mean_squared_error(predictions_2[i][0], Y_val[i, :, 1]))\n",
    "\n",
    "rmse /= len(predictions_2)    \n",
    "print(f\"RMSE for {columns_to_predict[1]} = {rmse}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37ba52b0c61c1d5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model on the test data\n",
    "predictions_1_test = []\n",
    "predictions_2_test = []\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for i in range(len(Y_test)):\n",
    "    current_batch = X_test[i].reshape((1, NUM_OF_TIMESTEPS_INPUT, NUM_OF_FEATURES))\n",
    "    start = time.time()\n",
    "    curr_pred1, curr_pred2 = model.predict(current_batch)\n",
    "    end = time.time()\n",
    "    total_time += end-start\n",
    "    predictions_1_test.append(curr_pred1)\n",
    "    predictions_2_test.append(curr_pred2)\n",
    "    \n",
    "print(f\"Average prediction time is {total_time/len(Y_test)} seconds\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdab6e586bf2147c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the test predictions for CI\n",
    "\n",
    "plt.figure(figsize=(20, 48))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for num, column in enumerate(predictions_1_test):\n",
    "    plt.subplot(9, 3, i)\n",
    "    i += 1\n",
    "    plt.plot(column[0], label=\"Prediction\")\n",
    "    plt.plot(Y_test[num, :, 0], label=\"Actual\")\n",
    "    plt.xlabel('Timestamp', fontsize=20)\n",
    "    plt.ylabel('Carbon Intensity (kg/kWh)', fontsize=20)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title(f'Prediction number {num+1}', fontsize=22)\n",
    "    plt.tick_params(labelsize=16)\n",
    "\n",
    "plt.suptitle('Predicted and actual Carbon Intensity', fontsize=26, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a6440aee56181bf",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot the test predictions for SG\n",
    "\n",
    "plt.figure(figsize=(20, 48))\n",
    "\n",
    "i = 1\n",
    "\n",
    "for num, column in enumerate(predictions_2_test):\n",
    "    plt.subplot(9, 3, i)\n",
    "    i += 1\n",
    "    plt.plot(column[0], label=\"Prediction\")\n",
    "    plt.plot(Y_test[num, :, 1], label=\"Actual\")\n",
    "    plt.xlabel('Timestamp', fontsize=20)\n",
    "    plt.ylabel('Carbon Intensity (kg/kWh)', fontsize=20)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.title(f'Prediction number {num+1}', fontsize=22)\n",
    "    plt.tick_params(labelsize=16)\n",
    "\n",
    "plt.suptitle('Predicted and actual Solar Generation', fontsize=26, y=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a58b5fd6aad16010",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the RMSE for the test predictions\n",
    "\n",
    "rmse = 0\n",
    "for i in range(len(predictions_1_test)):\n",
    "    rmse += sqrt(mean_squared_error(predictions_1_test[i][0], Y_test[i, :, 0]))\n",
    "\n",
    "rmse /= len(predictions_1_test)    \n",
    "print(f\"RMSE for {columns_to_predict[0]} = {rmse}\")\n",
    "\n",
    "rmse = 0\n",
    "for i in range(len(predictions_2_test)):\n",
    "    rmse += sqrt(mean_squared_error(predictions_2_test[i][0], Y_test[i, :, 1]))\n",
    "\n",
    "rmse /= len(predictions_2_test)    \n",
    "print(f\"RMSE for {columns_to_predict[1]} = {rmse}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4a0c0516ba6fa11",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Export the predictions\n",
    "\n",
    "a = []\n",
    "for column in predictions_1_test:\n",
    "    a.append(column[0])\n",
    "    \n",
    "b = []\n",
    "for column in predictions_2_test:\n",
    "    b.append(column[0])\n",
    "\n",
    "predictions1 = pd.DataFrame(a).T\n",
    "predictions1.to_csv('../data/results/carbon_gru.csv', index=False, header=False)\n",
    "predictions2 = pd.DataFrame(b).T\n",
    "predictions2.to_csv('../data/results/solar_gru.csv', index=False, header=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72f31a3d6abad7e",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
